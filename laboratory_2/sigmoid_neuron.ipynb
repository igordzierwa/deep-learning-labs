{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5c04ed",
   "metadata": {},
   "source": [
    "## Author: Igor Dzierwa\n",
    "## Laboratory 2 - Implementation of Gradient Descent for training a simple one-layer neural network\n",
    "\n",
    "Define the Sigmoid activation function.\n",
    "\n",
    "Define loss function as the squared differences between predicted and ground truth.\n",
    "\n",
    "Define derivative of activation function.\n",
    "\n",
    "Define derivative of loss function.\n",
    "\n",
    "Train the network:\n",
    "1. Take an example and feed it to the network.\n",
    "2. Calculate its gradient.\n",
    "3. Update the weights using the calculated gradient.\n",
    "\n",
    "Repeat the above steps for all the examples.\n",
    "\n",
    "This approach is calledStochastic Gradient Descent.\n",
    "\n",
    "```Python\n",
    "data = [[0.08,0.72,1.0],[0.01,1.00,0.0],[0.26,0.58,1.0],[0.35,0.95,0.0],[0.45,0.15,1.0],[0.60,0.30,1.0],[0.70,0.65,0.0],[0.92,0.45,0.0]]\n",
    "\n",
    "weights = [1.00,-1.00]\n",
    "\n",
    "bias = 0.20\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4984eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuronSigmoid:\n",
    "    def __init__(self, weights=None, bias=None):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    \n",
    "    def perceptron(self, x):\n",
    "        return np.dot(x, self.weights.T) + self.bias\n",
    "  \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1.0 + np.exp(-x))\n",
    "  \n",
    "    def gradient_weight(self, x, y):\n",
    "        y_pred = self.sigmoid(self.perceptron(x))\n",
    "        return (y_pred - y) * y_pred * (1 - y_pred) * x\n",
    "  \n",
    "    def gradient_bias(self, x, y):\n",
    "        y_pred = self.sigmoid(self.perceptron(x))\n",
    "        return (y_pred - y) * y_pred * (1 - y_pred)\n",
    "  \n",
    "    def fit(self, data_x, data_y, epoch_count=100, learning_rate=1, init=True):\n",
    "        if init:\n",
    "            self.weights = np.random.randn(1, data_x.shape[1])\n",
    "            self.bias = 1\n",
    "    \n",
    "        for i in range(epoch_count):\n",
    "            derivative_weights = 0\n",
    "            derivative_bias = 0\n",
    "        \n",
    "            for x, y in zip(data_x, data_y):\n",
    "                derivative_weights += self.gradient_weight(x, y)\n",
    "                derivative_bias += self.gradient_bias(x, y)\n",
    "            \n",
    "            self.weights -= learning_rate * derivative_weights\n",
    "            self.bias -= learning_rate * derivative_bias\n",
    "\n",
    "    def predict(self, data_x):\n",
    "        output = []\n",
    "        y_pred = self.sigmoid(self.perceptron(data_x))\n",
    "        output.append(y_pred)\n",
    "        return np.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468604b",
   "metadata": {},
   "source": [
    "#### Initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e35693e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [0.08,0.72,1.0],\n",
    "    [0.01,1.00,0.0],\n",
    "    [0.26,0.58,1.0],\n",
    "    [0.35,0.95,0.0],\n",
    "    [0.45,0.15,1.0],\n",
    "    [0.60,0.30,1.0],\n",
    "    [0.70,0.65,0.0],\n",
    "    [0.92,0.45,0.0]\n",
    "]\n",
    "    \n",
    "data_x = np.array([i[:2] for i in data])\n",
    "data_y = np.array([i[-1] for i in data]) \n",
    "    \n",
    "weights = np.array([1.00,-1.00])\n",
    "\n",
    "bias = 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b86b3c",
   "metadata": {},
   "source": [
    "#### Train SigmoidNeuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9619be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_neuron = NeuronSigmoid(weights, bias)\n",
    "\n",
    "sigmoid_neuron.fit(data_x, data_y, 5000, 0.5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e29187",
   "metadata": {},
   "source": [
    "#### Predict values based on trained SigmoidNeuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e98dbcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desired values:\n",
      " [1. 0. 1. 0. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Desired values:\\n {data_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9589b9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values:\n",
      " [[0.89295623 0.10718662 0.9281229  0.00567957 0.99970059 0.9750167\n",
      "  0.02157806 0.05958974]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted values:\\n {sigmoid_neuron.predict(data_x)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
